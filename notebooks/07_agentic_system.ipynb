{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861fe7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph & Libraries Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from typing import Annotated, TypedDict, List\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangGraph Imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Vector DB & Memory\n",
    "from pinecone import Pinecone\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Keyword Search & Processing\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pypdf\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import nltk\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "project_root = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Download NLTK data (if needed)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "print(\"LangGraph & Libraries Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada7321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configs & Models Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load configs from previous phases\n",
    "configs = {}\n",
    "for phase in range(1, 7):\n",
    "    try:\n",
    "        with open(project_root / f\"phase{phase}_config.json\", 'r') as f:\n",
    "            configs[f\"phase{phase}\"] = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Warning: phase{phase}_config.json not found\")\n",
    "\n",
    "# Initialize LLM & Embeddings\n",
    "llm = ChatGroq(\n",
    "    model_name=configs['phase4']['llm_model'], \n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=configs['phase2']['embedding_model'])\n",
    "reranker = CrossEncoder(configs['phase5']['cross_encoder'])\n",
    "\n",
    "print(\" Configs & Models Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953220f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to Pinecone & MongoDB\n"
     ]
    }
   ],
   "source": [
    "# 1. Pinecone (Vector DB)\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "disease_index = pc.Index(configs['phase2']['disease_index'])\n",
    "scheme_index = pc.Index(configs['phase2']['scheme_index'])\n",
    "\n",
    "# 2. MongoDB (Memory) - Use env variable directly with SSL fix\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\")\n",
    "\n",
    "mongo_connected = False\n",
    "try:\n",
    "    import certifi\n",
    "    \n",
    "    # Use certifi's CA bundle for SSL\n",
    "    if \"mongodb+srv\" in MONGODB_URI or \"mongodb.net\" in MONGODB_URI:\n",
    "        mongo_client = MongoClient(\n",
    "            MONGODB_URI,\n",
    "            tlsCAFile=certifi.where(),\n",
    "            serverSelectionTimeoutMS=5000\n",
    "        )\n",
    "    else:\n",
    "        mongo_client = MongoClient(MONGODB_URI)\n",
    "    \n",
    "    db = mongo_client[configs['phase3']['database']]\n",
    "    conversations_col = db[configs['phase3']['collections']['conversations']]\n",
    "    \n",
    "    # Test connection\n",
    "    mongo_client.admin.command('ping')\n",
    "    mongo_connected = True\n",
    "    print(\" Connected to Pinecone & MongoDB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ MongoDB connection issue: {e}\")\n",
    "    print(\"   Continuing without memory (stateless mode)\")\n",
    "    conversations_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cc7163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rebuilding BM25 Indices...\n",
      " BM25 Indices Ready\n"
     ]
    }
   ],
   "source": [
    "# Build BM25 Indices\n",
    "print(\" Rebuilding BM25 Indices...\")\n",
    "\n",
    "def load_and_process_pdf(pdf_name, index_prefix):\n",
    "    pdf_path = project_root / \"data\" / pdf_name\n",
    "    reader = pypdf.PdfReader(pdf_path)\n",
    "    text = \"\".join([p.extract_text() for p in reader.pages])\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=configs['phase1']['chunking']['size'],\n",
    "        chunk_overlap=configs['phase1']['chunking']['overlap'],\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    \n",
    "    docs = []\n",
    "    for i, content in enumerate(chunks):\n",
    "        docs.append({\n",
    "            \"id\": f\"{index_prefix}_{i}\",\n",
    "            \"content\": content,\n",
    "            \"metadata\": {\"source\": pdf_name}\n",
    "        })\n",
    "    return docs, BM25Okapi([word_tokenize(d['content'].lower()) for d in docs])\n",
    "\n",
    "# Build Indices\n",
    "disease_docs, bm25_disease = load_and_process_pdf(\"CitrusPlantPestsAndDiseases.pdf\", configs['phase2']['disease_index'])\n",
    "scheme_docs, bm25_scheme = load_and_process_pdf(\"GovernmentSchemes.pdf\", configs['phase2']['scheme_index'])\n",
    "\n",
    "print(\" BM25 Indices Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc1e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypedDict for Agent State\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    chat_history: str\n",
    "    intent: str\n",
    "    documents: List[dict]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b2a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NODE 1: INTENT CLASSIFIER \n",
    "def intent_node(state: AgentState):\n",
    "    print(\" Analyzing Intent...\")\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an intent classifier for an agriculture bot.\n",
    "    Classify the query into exactly one of these categories:\n",
    "    - disease (crop pests, diseases, symptoms, treatments)\n",
    "    - scheme (government schemes, subsidies, insurance, loans)\n",
    "    - hybrid (how schemes help with diseases)\n",
    "    - unclear (greetings, off-topic, nonsense)\n",
    "    \n",
    "    Return ONLY the category name in lowercase.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt), \n",
    "        (\"user\", f\"History: {state['chat_history']}\\nQuery: {state['question']}\")\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    intent = chain.invoke({}).strip().lower()\n",
    "    \n",
    "    # Fallback cleanup\n",
    "    valid_intents = [\"disease\", \"scheme\", \"hybrid\", \"unclear\"]\n",
    "    if intent not in valid_intents:\n",
    "        intent = \"unclear\"\n",
    "        \n",
    "    return {\"intent\": intent}\n",
    "\n",
    "\n",
    "#  NODE 2: RETRIEVER (Hybrid + Rerank) \n",
    "def retrieval_node(state: AgentState):\n",
    "    print(f\"ðŸ“‚ Retrieving for intent: {state['intent']}...\")\n",
    "    query = state['question']\n",
    "    intent = state['intent']\n",
    "    \n",
    "    docs = []\n",
    "    \n",
    "    # Helper for Hybrid Search\n",
    "    def run_hybrid(index, bm25, raw_docs, source_name):\n",
    "        results = []\n",
    "        \n",
    "        # 1. Vector Search\n",
    "        vec_res = index.query(vector=embeddings.embed_query(query), top_k=5, include_metadata=True)\n",
    "        for m in vec_res.matches:\n",
    "            # Normalize structure: always use nested metadata\n",
    "            results.append({\n",
    "                \"id\": m.id,\n",
    "                \"content\": m.metadata.get('text', ''),\n",
    "                \"metadata\": {\"source\": m.metadata.get('source', source_name)}\n",
    "            })\n",
    "        \n",
    "        # 2. Keyword Search\n",
    "        tokens = word_tokenize(query.lower())\n",
    "        scores = bm25.get_scores(tokens)\n",
    "        top_n = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "        for i in top_n:\n",
    "            if scores[i] > 0:\n",
    "                results.append(raw_docs[i])  # Already has correct structure\n",
    "        \n",
    "        return results\n",
    "\n",
    "    # Route to correct indexes\n",
    "    if intent in ['disease', 'hybrid']:\n",
    "        docs.extend(run_hybrid(disease_index, bm25_disease, disease_docs, \"CitrusPlantPestsAndDiseases.pdf\"))\n",
    "    if intent in ['scheme', 'hybrid']:\n",
    "        docs.extend(run_hybrid(scheme_index, bm25_scheme, scheme_docs, \"GovernmentSchemes.pdf\"))\n",
    "    \n",
    "    # Deduplicate\n",
    "    unique_docs = {d['content']: d for d in docs}.values()\n",
    "    \n",
    "    # Rerank\n",
    "    if not unique_docs: return {\"documents\": []}\n",
    "    \n",
    "    pairs = [[query, d['content']] for d in unique_docs]\n",
    "    scores = reranker.predict(pairs)\n",
    "    ranked = sorted(zip(unique_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Keep top 4\n",
    "    return {\"documents\": [d[0] for d in ranked[:4]]}\n",
    "\n",
    "\n",
    "# NODE 3: GENERATOR\n",
    "def generation_node(state: AgentState):\n",
    "    print(\" Generating Answer...\")\n",
    "    \n",
    "    if not state['documents']:\n",
    "        return {\"answer\": \"I could not find any relevant documents to answer your question.\"}\n",
    "    \n",
    "    context_str = \"\\n\\n\".join([f\"Source: {d['metadata']['source']}\\n{d['content']}\" for d in state['documents']])\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert Agricultural Assistant.\n",
    "    Answer the user's question using ONLY the context provided.\n",
    "    Always cite the Source Documents at the end of your answer.\n",
    "    If the context is empty, say you don't know.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", f\"Context:\\n{context_str}\\n\\nHistory:\\n{state['chat_history']}\\n\\nQuestion: {state['question']}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    return {\"answer\": chain.invoke({})}\n",
    "\n",
    "\n",
    "#  NODE 4: CLARIFICATION \n",
    "def clarification_node(state: AgentState):\n",
    "    print(\" Asking for Clarification...\")\n",
    "    return {\"answer\": \"I am not sure if you are asking about a crop disease or a government scheme. Could you please clarify or provide more details?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac88cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Agent Compiled!\n"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "#  Adding  Nodes\n",
    "workflow.add_node(\"classifier\", intent_node)\n",
    "workflow.add_node(\"retriever\", retrieval_node)\n",
    "workflow.add_node(\"generator\", generation_node)\n",
    "workflow.add_node(\"clarifier\", clarification_node)\n",
    "\n",
    "# Entry Point\n",
    "workflow.set_entry_point(\"classifier\")\n",
    "\n",
    "#  Add Conditional Routing\n",
    "def route_intent(state):\n",
    "    if state[\"intent\"] == \"unclear\":\n",
    "        return \"clarifier\"\n",
    "    return \"retriever\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"classifier\",\n",
    "    route_intent,\n",
    "    {\n",
    "        \"clarifier\": \"clarifier\",\n",
    "        \"retriever\": \"retriever\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Linear Edges\n",
    "workflow.add_edge(\"retriever\", \"generator\")\n",
    "workflow.add_edge(\"generator\", END)\n",
    "workflow.add_edge(\"clarifier\", END)\n",
    "\n",
    "#  Compile\n",
    "app = workflow.compile()\n",
    "print(\" Agent Compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc83c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to run the graph\n",
    "def run_agent(question, session_id=\"test_session\"):\n",
    "    # Get history from MongoDB (with error handling)\n",
    "    chat_history = \"\"\n",
    "    if conversations_col is not None:\n",
    "        try:\n",
    "            history_doc = conversations_col.find_one({\"session_id\": session_id})\n",
    "            if history_doc:\n",
    "                chat_history = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in history_doc['messages'][-4:]])\n",
    "        except Exception as e:\n",
    "            print(f\" Could not fetch history: {e}\")\n",
    "    \n",
    "    inputs = {\n",
    "        \"question\": question,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"intent\": \"\",\n",
    "        \"documents\": [],\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n USER: {question}\")\n",
    "    result = app.invoke(inputs)\n",
    "    print(f\" BOT: {result['answer']}\")\n",
    "    \n",
    "    # Save to MongoDB (with error handling)\n",
    "    if conversations_col is not None:\n",
    "        try:\n",
    "            conversations_col.update_one(\n",
    "                {\"session_id\": session_id},\n",
    "                {\"$push\": {\"messages\": {\"$each\": [\n",
    "                    {\"role\": \"user\", \"content\": question, \"timestamp\": time.time()},\n",
    "                    {\"role\": \"assistant\", \"content\": result['answer'], \"timestamp\": time.time()}\n",
    "                ]}}},\n",
    "                upsert=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\" Could not save to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9a291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " USER: What are symptoms of Citrus Canker?\n",
      " Analyzing Intent...\n",
      "ðŸ“‚ Retrieving for intent: disease...\n",
      " Generating Answer...\n",
      " BOT: The symptoms of Citrus Canker include: \n",
      "1. Corky brown lesions with yellow halos on leaves, fruit, twigs; \n",
      "2. Premature leaf/fruit drop.\n",
      "\n",
      "Source: CitrusPlantPestsAndDiseases.pdf [31, 33]\n",
      "\n",
      " USER: How much subsidy for Drip Irrigation?\n",
      " Analyzing Intent...\n",
      "ðŸ“‚ Retrieving for intent: scheme...\n",
      " Generating Answer...\n",
      " BOT: \n",
      "fit\n",
      "Rs. 4,50,000\n",
      "approx\n",
      "Source: GovernmentSchemes.pdf\n",
      "\n",
      " USER: tell me something random\n",
      " Analyzing Intent...\n",
      " Asking for Clarification...\n",
      " BOT: I am not sure if you are asking about a crop disease or a government scheme. Could you please clarify or provide more details?\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Disease\n",
    "run_agent(\"What are symptoms of Citrus Canker?\", \"demo_1\")\n",
    "\n",
    "# Test 2: Scheme\n",
    "run_agent(\"How much subsidy for Drip Irrigation?\", \"demo_1\")\n",
    "\n",
    "# Test 3: Unclear (Should trigger Clarifier)\n",
    "run_agent(\"tell me something random\", \"demo_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a28138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agri-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
