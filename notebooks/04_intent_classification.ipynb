{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe51016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "project_root = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\" Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45476e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All imports successful\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "# LangChain with Groq instead of Gemini\n",
    "from langchain_groq import ChatGroq  \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "print(\" All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d2aaf",
   "metadata": {},
   "source": [
    "### 1. Load Previous Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b865f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Phase 2 config loaded\n",
      "   Disease index: agri-chatbot-disease\n",
      "   Scheme index: agri-chatbot-scheme\n",
      " Phase 3 config loaded\n",
      "   Database: agri_chatbot\n"
     ]
    }
   ],
   "source": [
    "# Load Phase 2 & 3 configs\n",
    "phase2_config_path = project_root / \"phase2_config.json\"\n",
    "phase3_config_path = project_root / \"phase3_config.json\"\n",
    "\n",
    "if phase2_config_path.exists():\n",
    "    with open(phase2_config_path, 'r') as f:\n",
    "        phase2_config = json.load(f)\n",
    "    print(\" Phase 2 config loaded\")\n",
    "    print(f\"   Disease index: {phase2_config['disease_index']}\")\n",
    "    print(f\"   Scheme index: {phase2_config['scheme_index']}\")\n",
    "\n",
    "if phase3_config_path.exists():\n",
    "    with open(phase3_config_path, 'r') as f:\n",
    "        phase3_config = json.load(f)\n",
    "    print(\" Phase 3 config loaded\")\n",
    "    print(f\"   Database: {phase3_config['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78130928",
   "metadata": {},
   "source": [
    "### 2. Define Intent Types & Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e755be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Intent schema defined\n",
      "\n",
      "Intent types:\n",
      "   ‚Ä¢ disease\n",
      "   ‚Ä¢ scheme\n",
      "   ‚Ä¢ hybrid\n",
      "   ‚Ä¢ unclear\n"
     ]
    }
   ],
   "source": [
    "class IntentType(str, Enum):\n",
    "    \"\"\"Possible intent types\"\"\"\n",
    "    DISEASE = \"disease\"\n",
    "    SCHEME = \"scheme\"\n",
    "    HYBRID = \"hybrid\"\n",
    "    UNCLEAR = \"unclear\"\n",
    "\n",
    "class IntentClassification(BaseModel):\n",
    "    \"\"\"Intent classification result schema\"\"\"\n",
    "    intent: str = Field(description=\"Classified intent: disease, scheme, hybrid, or unclear\")\n",
    "    confidence: float = Field(description=\"Confidence score (0.0 to 1.0)\")\n",
    "    reasoning: str = Field(description=\"Brief explanation for the classification\")\n",
    "    entities: Dict[str, List[str]] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Extracted entities (diseases, schemes, locations, etc.)\"\n",
    "    )\n",
    "    needs_clarification: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the query needs clarification\"\n",
    "    )\n",
    "    clarification_question: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Clarification question if needed\"\n",
    "    )\n",
    "\n",
    "print(\" Intent schema defined\")\n",
    "print(\"\\nIntent types:\")\n",
    "for intent in IntentType:\n",
    "    print(f\"   ‚Ä¢ {intent.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a277943",
   "metadata": {},
   "source": [
    "### 3. Initialize Groq LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6363b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Groq LLM initialized\n",
      "   Model: llama-3.3-70b-versatile\n",
      "   Temperature: 0\n"
     ]
    }
   ],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY or GROQ_API_KEY == \"your_groq_api_key_here\":\n",
    "    print(\" GROQ_API_KEY not found in .env\")\n",
    "    print(\"  Please add your API key to continue\")\n",
    "else:\n",
    "    # Initialize Groq LLM\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.3-70b-versatile\",  # Fast and capable model\n",
    "        temperature=0,\n",
    "        api_key=GROQ_API_KEY\n",
    "    )\n",
    "    \n",
    "    print(\" Groq LLM initialized\")\n",
    "    print(f\"   Model: llama-3.3-70b-versatile\")\n",
    "    print(f\"   Temperature: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4e03a",
   "metadata": {},
   "source": [
    "### 4. Create Intent Classification Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadef683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Intent classification chain created\n"
     ]
    }
   ],
   "source": [
    "intent_classification_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert agricultural assistant specializing in citrus farming.\n",
    "Your task is to classify farmer queries into one of these intents:\n",
    "\n",
    "1. **disease**: Query about citrus diseases, pests, symptoms, treatment, prevention\n",
    "   Examples: \"yellow leaves\", \"citrus canker treatment\", \"whitefly control\"\n",
    "\n",
    "2. **scheme**: Query about government schemes, subsidies, financial assistance\n",
    "   Examples: \"drip irrigation subsidy\", \"PMKSY scheme\", \"loan for farmers\"\n",
    "\n",
    "3. **hybrid**: Query combining BOTH disease/pest issues AND government support\n",
    "   Examples: \"schemes for disease management\", \"subsidy for pest control equipment\"\n",
    "\n",
    "4. **unclear**: Query is too vague or ambiguous to classify\n",
    "   Examples: \"help me\", \"what should I do\", \"tell me about citrus\"\n",
    "\n",
    "**Classification Rules:**\n",
    "- If query mentions BOTH a disease/pest AND financial help ‚Üí hybrid\n",
    "- If query only about disease/pest management ‚Üí disease\n",
    "- If query only about schemes/subsidies ‚Üí scheme\n",
    "- If query is too general or vague ‚Üí unclear (provide clarification question)\n",
    "\n",
    "**Context provided:** {context}\n",
    "\n",
    "**IMPORTANT: You MUST respond with a valid JSON object with ALL these fields:**\n",
    "{{\n",
    "    \"intent\": \"disease|scheme|hybrid|unclear\",\n",
    "    \"confidence\": 0.85,\n",
    "    \"reasoning\": \"Brief explanation for classification\",\n",
    "    \"entities\": {{\"diseases\": [], \"schemes\": [], \"locations\": []}},\n",
    "    \"needs_clarification\": false,\n",
    "    \"clarification_question\": null\n",
    "}}\n",
    "\n",
    "**DO NOT include any text before or after the JSON. ONLY return the JSON object.**\"\"\"),\n",
    "    (\"user\", \"Query: {query}\")\n",
    "])\n",
    "\n",
    "# Setup output parser with better error handling\n",
    "parser = JsonOutputParser(pydantic_object=IntentClassification)\n",
    "\n",
    "# Create chain\n",
    "intent_chain = intent_classification_prompt | llm | parser\n",
    "\n",
    "print(\" Intent classification chain created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a82a4",
   "metadata": {},
   "source": [
    "### 5. Build Intent Classifier Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a0f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Intent classifier function ready (with error handling)\n"
     ]
    }
   ],
   "source": [
    "def classify_intent(\n",
    "    query: str,\n",
    "    conversation_context: Optional[str] = None\n",
    ") -> IntentClassification:\n",
    "    \"\"\"\n",
    "    Classify query intent with optional conversation context\n",
    "    \n",
    "    Args:\n",
    "        query: User's query\n",
    "        conversation_context: Previous conversation history (optional)\n",
    "    \n",
    "    Returns:\n",
    "        IntentClassification object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build context string\n",
    "    context_str = \"No previous conversation.\"\n",
    "    if conversation_context:\n",
    "        context_str = f\"Previous conversation:\\n{conversation_context}\"\n",
    "    \n",
    "    try:\n",
    "        # Invoke chain\n",
    "        result = intent_chain.invoke({\n",
    "            \"query\": query,\n",
    "            \"context\": context_str\n",
    "        })\n",
    "        \n",
    "        # Ensure all required fields exist with defaults\n",
    "        result.setdefault(\"confidence\", 0.7)\n",
    "        result.setdefault(\"reasoning\", \"Classification based on query analysis\")\n",
    "        result.setdefault(\"entities\", {})\n",
    "        result.setdefault(\"needs_clarification\", False)\n",
    "        result.setdefault(\"clarification_question\", None)\n",
    "        \n",
    "        return IntentClassification(**result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Classification error: {e}\")\n",
    "        print(f\" Raw result: {result}\")\n",
    "        \n",
    "        # Fallback: try to fix the result\n",
    "        fixed_result = {\n",
    "            \"intent\": result.get(\"intent\", \"unclear\"),\n",
    "            \"confidence\": result.get(\"confidence\", 0.5),\n",
    "            \"reasoning\": result.get(\"reasoning\", \"Unable to classify with full confidence\"),\n",
    "            \"entities\": result.get(\"entities\", {}),\n",
    "            \"needs_clarification\": result.get(\"needs_clarification\", True),\n",
    "            \"clarification_question\": result.get(\"clarification_question\", \n",
    "                                                \"Could you provide more details about your query?\")\n",
    "        }\n",
    "        \n",
    "        return IntentClassification(**fixed_result)\n",
    "\n",
    "print(\" Intent classifier function ready (with error handling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1c3e7",
   "metadata": {},
   "source": [
    "### 6. Test Intent Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c416faff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Query: My citrus leaves are showing yellow blotchy patches. What could this be?\n",
      "\n",
      " Classification Result:\n",
      "   Intent: disease\n",
      "   Confidence: 0.90\n",
      "   Reasoning: The query mentions a specific symptom (yellow blotchy patches on citrus leaves) which is likely related to a disease or pest issue\n",
      "   Entities: {'diseases': ['citrus canker'], 'schemes': [], 'locations': []}\n",
      "   Needs clarification: False\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Clear disease query\n",
    "query1 = \"My citrus leaves are showing yellow blotchy patches. What could this be?\"\n",
    "\n",
    "result1 = classify_intent(query1)\n",
    "\n",
    "print(\" Query:\", query1)\n",
    "print(f\"\\n Classification Result:\")\n",
    "print(f\"   Intent: {result1.intent}\")\n",
    "print(f\"   Confidence: {result1.confidence:.2f}\")\n",
    "print(f\"   Reasoning: {result1.reasoning}\")\n",
    "print(f\"   Entities: {result1.entities}\")\n",
    "print(f\"   Needs clarification: {result1.needs_clarification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3893ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: What government schemes are available for citrus farmers in Andhra Pradesh?\n",
      "\n",
      " Classification Result:\n",
      "   Intent: scheme\n",
      "   Confidence: 0.90\n",
      "   Reasoning: The query specifically asks about government schemes for citrus farmers in a particular location, Andhra Pradesh, without mentioning any disease or pest issues.\n",
      "   Entities: {'diseases': [], 'schemes': ['government schemes'], 'locations': ['Andhra Pradesh']}\n",
      "   Needs clarification: False\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Clear scheme query\n",
    "query2 = \"What government schemes are available for citrus farmers in Andhra Pradesh?\"\n",
    "\n",
    "result2 = classify_intent(query2)\n",
    "\n",
    "print(\"üîç Query:\", query2)\n",
    "print(f\"\\n Classification Result:\")\n",
    "print(f\"   Intent: {result2.intent}\")\n",
    "print(f\"   Confidence: {result2.confidence:.2f}\")\n",
    "print(f\"   Reasoning: {result2.reasoning}\")\n",
    "print(f\"   Entities: {result2.entities}\")\n",
    "print(f\"   Needs clarification: {result2.needs_clarification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28062f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: What government schemes can help me manage Citrus Greening disease in my farm?\n",
      "\n",
      " Classification Result:\n",
      "   Intent: hybrid\n",
      "   Confidence: 0.90\n",
      "   Reasoning: The query mentions both a disease (Citrus Greening) and government schemes, which aligns with the hybrid intent.\n",
      "   Entities: {'diseases': ['Citrus Greening'], 'schemes': [], 'locations': []}\n",
      "   Needs clarification: False\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Hybrid query\n",
    "query3 = \"What government schemes can help me manage Citrus Greening disease in my farm?\"\n",
    "\n",
    "result3 = classify_intent(query3)\n",
    "\n",
    "print(\"üîç Query:\", query3)\n",
    "print(f\"\\n Classification Result:\")\n",
    "print(f\"   Intent: {result3.intent}\")\n",
    "print(f\"   Confidence: {result3.confidence:.2f}\")\n",
    "print(f\"   Reasoning: {result3.reasoning}\")\n",
    "print(f\"   Entities: {result3.entities}\")\n",
    "print(f\"   Needs clarification: {result3.needs_clarification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83920ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: Tell me about citrus\n",
      "\n",
      "üìä Classification Result:\n",
      "   Intent: unclear\n",
      "   Confidence: 0.80\n",
      "   Reasoning: The query is too general and does not specify a particular aspect of citrus farming.\n",
      "   Needs clarification: True\n",
      "\n",
      "üí¨ Clarification Question:\n",
      "   What specific aspect of citrus farming would you like to know about, such as diseases, cultivation, or government schemes?\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Unclear/vague query\n",
    "query4 = \"Tell me about citrus\"\n",
    "\n",
    "result4 = classify_intent(query4)\n",
    "\n",
    "print(\"üîç Query:\", query4)\n",
    "print(f\"\\nüìä Classification Result:\")\n",
    "print(f\"   Intent: {result4.intent}\")\n",
    "print(f\"   Confidence: {result4.confidence:.2f}\")\n",
    "print(f\"   Reasoning: {result4.reasoning}\")\n",
    "print(f\"   Needs clarification: {result4.needs_clarification}\")\n",
    "if result4.clarification_question:\n",
    "    print(f\"\\nüí¨ Clarification Question:\")\n",
    "    print(f\"   {result4.clarification_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42966fb2",
   "metadata": {},
   "source": [
    "### 7. Test Context-Aware Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d5fcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Context:\n",
      "USER: My citrus leaves are showing yellow blotchy patches\n",
      "ASSISTANT: This could be Huanglongbing (HLB) disease. Symptoms include asymmetrical mottling on leaves.\n",
      "\n",
      " Follow-up Query: 'How do I prevent it?'\n",
      "\n",
      " Classification with Context:\n",
      "   Intent: disease\n",
      "   Confidence: 0.90\n",
      "   Reasoning: The user is asking for prevention methods, which is directly related to disease management, following the previous conversation about Huanglongbing (HLB) disease.\n",
      "\n",
      " Classification WITHOUT Context:\n",
      "   Intent: unclear\n",
      "   Confidence: 0.80\n",
      "   Reasoning: The query is too vague and does not specify what needs to be prevented.\n"
     ]
    }
   ],
   "source": [
    "# Simulate conversation context from previous conversation\n",
    "conversation_context = \"\"\"USER: My citrus leaves are showing yellow blotchy patches\n",
    "ASSISTANT: This could be Huanglongbing (HLB) disease. Symptoms include asymmetrical mottling on leaves.\"\"\"\n",
    "\n",
    "# Follow-up query (pronoun reference - \"it\")\n",
    "follow_up_query = \"How do I prevent it?\"\n",
    "\n",
    "result_context = classify_intent(follow_up_query, conversation_context)\n",
    "\n",
    "print(\"Previous Context:\")\n",
    "print(conversation_context)\n",
    "print(f\"\\n Follow-up Query: '{follow_up_query}'\")\n",
    "print(f\"\\n Classification with Context:\")\n",
    "print(f\"   Intent: {result_context.intent}\")\n",
    "print(f\"   Confidence: {result_context.confidence:.2f}\")\n",
    "print(f\"   Reasoning: {result_context.reasoning}\")\n",
    "\n",
    "# Compare with no context\n",
    "result_no_context = classify_intent(follow_up_query)\n",
    "print(f\"\\n Classification WITHOUT Context:\")\n",
    "print(f\"   Intent: {result_no_context.intent}\")\n",
    "print(f\"   Confidence: {result_no_context.confidence:.2f}\")\n",
    "print(f\"   Reasoning: {result_no_context.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebfdd4",
   "metadata": {},
   "source": [
    "### 8. Batch Testing & Accuracy Measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0350e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Dataset: 19 queries\n",
      "\n",
      " Distribution:\n",
      "   ‚Ä¢ Disease: 5 queries\n",
      "   ‚Ä¢ Scheme: 5 queries\n",
      "   ‚Ä¢ Hybrid: 5 queries\n",
      "   ‚Ä¢ Unclear: 4 queries\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive test dataset with expected intents\n",
    "test_queries = [\n",
    "    # Disease queries\n",
    "    (\"What are the symptoms of citrus canker?\", \"disease\"),\n",
    "    (\"How to control whitefly infestation?\", \"disease\"),\n",
    "    (\"My leaves are turning yellow\", \"disease\"),\n",
    "    (\"Treatment for citrus greening\", \"disease\"),\n",
    "    (\"Pest control for citrus psyllid\", \"disease\"),\n",
    "    \n",
    "    # Scheme queries\n",
    "    (\"What subsidies are available for drip irrigation?\", \"scheme\"),\n",
    "    (\"How to apply for PMKSY scheme?\", \"scheme\"),\n",
    "    (\"Agricultural loan interest rates\", \"scheme\"),\n",
    "    (\"NHM scheme eligibility criteria\", \"scheme\"),\n",
    "    (\"Government support for organic farming\", \"scheme\"),\n",
    "    \n",
    "    # Hybrid queries\n",
    "    (\"Government support for pest control equipment?\", \"hybrid\"),\n",
    "    (\"Schemes for HLB disease management\", \"hybrid\"),\n",
    "    (\"Financial help for replanting diseased trees\", \"hybrid\"),\n",
    "    (\"Subsidy for disease resistant varieties\", \"hybrid\"),\n",
    "    (\"Government assistance for citrus canker control\", \"hybrid\"),\n",
    "    \n",
    "    # Unclear queries\n",
    "    (\"Tell me about farming\", \"unclear\"),\n",
    "    (\"Help me\", \"unclear\"),\n",
    "    (\"What should I do?\", \"unclear\"),\n",
    "    (\"Citrus\", \"unclear\"),\n",
    "]\n",
    "\n",
    "print(f\" Test Dataset: {len(test_queries)} queries\")\n",
    "print(\"\\n Distribution:\")\n",
    "print(f\"   ‚Ä¢ Disease: {sum(1 for _, intent in test_queries if intent == 'disease')} queries\")\n",
    "print(f\"   ‚Ä¢ Scheme: {sum(1 for _, intent in test_queries if intent == 'scheme')} queries\")\n",
    "print(f\"   ‚Ä¢ Hybrid: {sum(1 for _, intent in test_queries if intent == 'hybrid')} queries\")\n",
    "print(f\"   ‚Ä¢ Unclear: {sum(1 for _, intent in test_queries if intent == 'unclear')} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a0ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running batch classification...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22dc70da4ea471e94672a48b327610d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Batch classification complete: 19 queries\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "# Run classification on all test queries\n",
    "results = []\n",
    "\n",
    "print(\" Running batch classification...\\n\")\n",
    "\n",
    "for query, expected_intent in tqdm(test_queries, desc=\"Classifying\"):\n",
    "    try:\n",
    "        result = classify_intent(query)\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"expected\": expected_intent,\n",
    "            \"predicted\": result.intent,\n",
    "            \"confidence\": result.confidence,\n",
    "            \"reasoning\": result.reasoning,\n",
    "            \"correct\": result.intent == expected_intent\n",
    "        })\n",
    "        \n",
    "        # Small delay to respect rate limits\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n  Error classifying '{query}': {e}\")\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"expected\": expected_intent,\n",
    "            \"predicted\": \"error\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"reasoning\": str(e),\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "print(f\"\\n Batch classification complete: {len(results)} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44562ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " CLASSIFICATION ACCURACY REPORT\n",
      "======================================================================\n",
      "\n",
      " Overall Metrics:\n",
      "   Accuracy: 94.7% (18/19)\n",
      "   Average Confidence: 0.89\n",
      "\n",
      " Per-Category Performance:\n",
      "----------------------------------------------------------------------\n",
      "   DISEASE    ‚Üí 100.0% (5/5)  |  Avg Confidence: 0.91\n",
      "   HYBRID     ‚Üí  80.0% (4/5)  |  Avg Confidence: 0.90\n",
      "   SCHEME     ‚Üí 100.0% (5/5)  |  Avg Confidence: 0.90\n",
      "   UNCLEAR    ‚Üí 100.0% (4/4)  |  Avg Confidence: 0.85\n",
      "\n",
      " Misclassified Queries (1):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   1. \"Government support for pest control equipment?\"\n",
      "      Expected: hybrid | Got: scheme (confidence: 0.90)\n",
      "      Reasoning: The query is about government support for pest control equipment, which falls under schemes and subs...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall accuracy\n",
    "correct = sum(1 for r in results if r[\"correct\"])\n",
    "total = len(results)\n",
    "accuracy = (correct / total) * 100\n",
    "\n",
    "# Per-category metrics\n",
    "from collections import defaultdict\n",
    "category_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0, \"avg_confidence\": []})\n",
    "\n",
    "for r in results:\n",
    "    if r[\"predicted\"] != \"error\":  # Skip errors\n",
    "        expected = r[\"expected\"]\n",
    "        category_stats[expected][\"total\"] += 1\n",
    "        category_stats[expected][\"avg_confidence\"].append(r[\"confidence\"])\n",
    "        if r[\"correct\"]:\n",
    "            category_stats[expected][\"correct\"] += 1\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" CLASSIFICATION ACCURACY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n Overall Metrics:\")\n",
    "print(f\"   Accuracy: {accuracy:.1f}% ({correct}/{total})\")\n",
    "avg_conf = sum(r[\"confidence\"] for r in results if r[\"predicted\"] != \"error\") / len([r for r in results if r[\"predicted\"] != \"error\"])\n",
    "print(f\"   Average Confidence: {avg_conf:.2f}\")\n",
    "\n",
    "print(f\"\\n Per-Category Performance:\")\n",
    "print(\"-\"*70)\n",
    "for category in sorted(category_stats.keys()):\n",
    "    stats = category_stats[category]\n",
    "    cat_accuracy = (stats[\"correct\"] / stats[\"total\"]) * 100 if stats[\"total\"] > 0 else 0\n",
    "    avg_cat_conf = sum(stats[\"avg_confidence\"]) / len(stats[\"avg_confidence\"]) if stats[\"avg_confidence\"] else 0\n",
    "    \n",
    "    print(f\"   {category.upper():10} ‚Üí {cat_accuracy:5.1f}% ({stats['correct']}/{stats['total']})  |  Avg Confidence: {avg_cat_conf:.2f}\")\n",
    "\n",
    "# Show misclassifications\n",
    "misclassified = [r for r in results if not r[\"correct\"] and r[\"predicted\"] != \"error\"]\n",
    "if misclassified:\n",
    "    print(f\"\\n Misclassified Queries ({len(misclassified)}):\")\n",
    "    print(\"-\"*70)\n",
    "    for i, r in enumerate(misclassified, 1):\n",
    "        print(f\"\\n   {i}. \\\"{r['query']}\\\"\")\n",
    "        print(f\"      Expected: {r['expected']} | Got: {r['predicted']} (confidence: {r['confidence']:.2f})\")\n",
    "        print(f\"      Reasoning: {r['reasoning'][:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022a049",
   "metadata": {},
   "source": [
    "### 9. Clarification Question Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337f3e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enhanced classifier with clarification logic ready\n",
      "   Confidence threshold: 0.70\n"
     ]
    }
   ],
   "source": [
    "def classify_with_clarification(\n",
    "    query: str,\n",
    "    conversation_context: Optional[str] = None,\n",
    "    confidence_threshold: float = 0.7\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Classify query and determine if clarification is needed\n",
    "    \n",
    "    Args:\n",
    "        query: User's query\n",
    "        conversation_context: Previous conversation history\n",
    "        confidence_threshold: Minimum confidence to proceed without clarification\n",
    "    \n",
    "    Returns:\n",
    "        Dict with classification and recommended action\n",
    "    \"\"\"\n",
    "    \n",
    "    result = classify_intent(query, conversation_context)\n",
    "    \n",
    "    response = {\n",
    "        \"intent\": result.intent,\n",
    "        \"confidence\": result.confidence,\n",
    "        \"reasoning\": result.reasoning,\n",
    "        \"entities\": result.entities,\n",
    "        \"action\": \"proceed\",  # \"proceed\" or \"clarify\"\n",
    "        \"clarification_question\": None\n",
    "    }\n",
    "    \n",
    "    # Determine if clarification is needed\n",
    "    needs_clarification = (\n",
    "        result.intent == \"unclear\" or \n",
    "        result.confidence < confidence_threshold or\n",
    "        result.needs_clarification\n",
    "    )\n",
    "    \n",
    "    if needs_clarification:\n",
    "        response[\"action\"] = \"clarify\"\n",
    "        \n",
    "        # Use LLM's clarification or generate default\n",
    "        if result.clarification_question:\n",
    "            response[\"clarification_question\"] = result.clarification_question\n",
    "        else:\n",
    "            response[\"clarification_question\"] = (\n",
    "                \"I want to help you better! Could you please specify:\\n\\n\"\n",
    "                \"1Ô∏è‚É£ Are you asking about disease symptoms or pest problems?\\n\"\n",
    "                \"2Ô∏è‚É£ Are you looking for government schemes or subsidies?\\n\"\n",
    "                \"3Ô∏è‚É£ Do you need both disease management advice AND financial support?\\n\\n\"\n",
    "                \"Please let me know which one applies to your situation.\"\n",
    "            )\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\" Enhanced classifier with clarification logic ready\")\n",
    "print(f\"   Confidence threshold: 0.70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd37aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Clarification Flow\n",
      "======================================================================\n",
      "\n",
      "üîç Query: \"help me with my farm\"\n",
      "----------------------------------------------------------------------\n",
      "   Intent: unclear\n",
      "   Confidence: 0.80\n",
      "   Action: CLARIFY\n",
      "\n",
      "    Clarification Question:\n",
      "   What specific issue are you facing with your citrus farm, such as disease management or financial assistance?\n",
      "\n",
      "üîç Query: \"what about citrus?\"\n",
      "----------------------------------------------------------------------\n",
      "   Intent: unclear\n",
      "   Confidence: 0.80\n",
      "   Action: CLARIFY\n",
      "\n",
      "    Clarification Question:\n",
      "   Could you please provide more details about what you would like to know about citrus, such as diseases, cultivation, or government schemes?\n",
      "\n",
      "üîç Query: \"I need information\"\n",
      "----------------------------------------------------------------------\n",
      "   Intent: unclear\n",
      "   Confidence: 0.90\n",
      "   Action: CLARIFY\n",
      "\n",
      "    Clarification Question:\n",
      "   Could you please provide more details about what kind of information you are looking for regarding citrus farming?\n",
      "\n",
      "üîç Query: \"tell me more\"\n",
      "----------------------------------------------------------------------\n",
      "   Intent: unclear\n",
      "   Confidence: 0.80\n",
      "   Action: CLARIFY\n",
      "\n",
      "    Clarification Question:\n",
      "   Could you please specify what you would like to know more about, such as citrus diseases, farming practices, or government schemes?\n",
      "\n",
      "üîç Query: \"schemes\"\n",
      "----------------------------------------------------------------------\n",
      "   Intent: scheme\n",
      "   Confidence: 0.90\n",
      "   Action: PROCEED\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with various ambiguous queries\n",
    "ambiguous_queries = [\n",
    "    \"help me with my farm\",\n",
    "    \"what about citrus?\",\n",
    "    \"I need information\",\n",
    "    \"tell me more\",\n",
    "    \"schemes\"  # Too vague\n",
    "]\n",
    "\n",
    "print(\" Testing Clarification Flow\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for query in ambiguous_queries:\n",
    "    print(f\"\\nüîç Query: \\\"{query}\\\"\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    response = classify_with_clarification(query)\n",
    "    \n",
    "    print(f\"   Intent: {response['intent']}\")\n",
    "    print(f\"   Confidence: {response['confidence']:.2f}\")\n",
    "    print(f\"   Action: {response['action'].upper()}\")\n",
    "    \n",
    "    if response['action'] == 'clarify':\n",
    "        print(f\"\\n    Clarification Question:\")\n",
    "        print(f\"   {response['clarification_question']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b9d95",
   "metadata": {},
   "source": [
    "### 10. Integration with MongoDB Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed327a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MongoDB connected\n",
      "   Found 4 conversations\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB (from Phase 3)\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\")\n",
    "\n",
    "try:\n",
    "    client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=3000)\n",
    "    client.admin.command('ping')\n",
    "    \n",
    "    db = client[\"agri_chatbot\"]\n",
    "    conversations = db[\"conversations\"]\n",
    "    \n",
    "    print(\" MongoDB connected\")\n",
    "    \n",
    "    # Check for existing conversations\n",
    "    conv_count = conversations.count_documents({})\n",
    "    print(f\"   Found {conv_count} conversations\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  MongoDB connection failed: {e}\")\n",
    "    print(\"   Phase 10 will work with sample data only\")\n",
    "    conversations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4ade1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context retrieval function ready\n"
     ]
    }
   ],
   "source": [
    "def get_conversation_context(session_id: str, max_messages: int = 4) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Retrieve conversation context from MongoDB\n",
    "    \n",
    "    Args:\n",
    "        session_id: Session ID to retrieve\n",
    "        max_messages: Maximum number of recent messages to include\n",
    "    \n",
    "    Returns:\n",
    "        Formatted context string or None\n",
    "    \"\"\"\n",
    "    \n",
    "    if conversations is None:\n",
    "        return None\n",
    "    \n",
    "    conversation = conversations.find_one({\"session_id\": session_id})\n",
    "    \n",
    "    if not conversation or not conversation.get(\"messages\"):\n",
    "        return None\n",
    "    \n",
    "    # Get last N messages\n",
    "    messages = conversation[\"messages\"][-max_messages:]\n",
    "    \n",
    "    # Format as context\n",
    "    context_parts = []\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"].upper()\n",
    "        content = msg[\"content\"]\n",
    "        context_parts.append(f\"{role}: {content}\")\n",
    "    \n",
    "    return \"\\n\".join(context_parts)\n",
    "\n",
    "print(\" Context retrieval function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46f24c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Real Conversation Context from MongoDB:\n",
      "======================================================================\n",
      "USER: How do I prevent it?\n",
      "ASSISTANT: Prevention includes: 1) Use disease-free nursery stock, 2) Apply copper sprays, 3) Control citrus leafminer, 4) Plant windbreaks.\n",
      "USER: Are there any government schemes for disease management?\n",
      "ASSISTANT: Yes, the National Horticulture Mission provides assistance for disease management and replanting with certified material.\n",
      "======================================================================\n",
      "\n",
      " Follow-up Query: \"Are there any subsidies for this?\"\n",
      "\n",
      " Classification Result:\n",
      "   Intent: scheme\n",
      "   Confidence: 0.90\n",
      "   Reasoning: The query is asking about subsidies, which is directly related to government schemes and financial assistance.\n",
      "   Action: proceed\n"
     ]
    }
   ],
   "source": [
    "# Test with real conversation data from MongoDB\n",
    "if conversations is not None:\n",
    "    # Get a sample session\n",
    "    sample_conv = conversations.find_one({})\n",
    "    \n",
    "    if sample_conv:\n",
    "        session_id = sample_conv[\"session_id\"]\n",
    "        context = get_conversation_context(session_id)\n",
    "        \n",
    "        print(\"üìñ Real Conversation Context from MongoDB:\")\n",
    "        print(\"=\"*70)\n",
    "        print(context)\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Test follow-up query\n",
    "        follow_up = \"Are there any subsidies for this?\"\n",
    "        \n",
    "        print(f\"\\n Follow-up Query: \\\"{follow_up}\\\"\")\n",
    "        \n",
    "        result = classify_with_clarification(follow_up, context)\n",
    "        \n",
    "        print(f\"\\n Classification Result:\")\n",
    "        print(f\"   Intent: {result['intent']}\")\n",
    "        print(f\"   Confidence: {result['confidence']:.2f}\")\n",
    "        print(f\"   Reasoning: {result['reasoning']}\")\n",
    "        print(f\"   Action: {result['action']}\")\n",
    "        \n",
    "        if result['action'] == 'clarify':\n",
    "            print(f\"\\n Clarification:\")\n",
    "            print(f\"   {result['clarification_question']}\")\n",
    "    else:\n",
    "        print(\" No conversations found in MongoDB\")\n",
    "else:\n",
    "    print(\"  MongoDB not available\")\n",
    "    print(\"   Run Phase 3 notebook to create test conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b8f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Phase 4 config saved\n",
      "   Location: /Users/kaushik003/Documents/projects/agri-chatbot/phase4_config.json\n",
      "\n",
      " Configuration Summary:\n",
      "{\n",
      "  \"llm_provider\": \"groq\",\n",
      "  \"llm_model\": \"llama-3.3-70b-versatile\",\n",
      "  \"temperature\": 0,\n",
      "  \"intent_types\": [\n",
      "    \"disease\",\n",
      "    \"scheme\",\n",
      "    \"hybrid\",\n",
      "    \"unclear\"\n",
      "  ],\n",
      "  \"confidence_threshold\": 0.7,\n",
      "  \"max_context_messages\": 4,\n",
      "  \"test_results\": {\n",
      "    \"total_queries\": 19,\n",
      "    \"accuracy\": \"94.7%\",\n",
      "    \"avg_confidence\": \"0.89\",\n",
      "    \"per_category\": {\n",
      "      \"disease\": {\n",
      "        \"accuracy\": \"100.0%\",\n",
      "        \"total\": 5\n",
      "      },\n",
      "      \"scheme\": {\n",
      "        \"accuracy\": \"100.0%\",\n",
      "        \"total\": 5\n",
      "      },\n",
      "      \"hybrid\": {\n",
      "        \"accuracy\": \"80.0%\",\n",
      "        \"total\": 5\n",
      "      },\n",
      "      \"unclear\": {\n",
      "        \"accuracy\": \"100.0%\",\n",
      "        \"total\": 4\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"features\": [\n",
      "    \"intent_classification\",\n",
      "    \"clarification_generation\",\n",
      "    \"context_aware_classification\",\n",
      "    \"entity_extraction\",\n",
      "    \"mongodb_integration\"\n",
      "  ],\n",
      "  \"created_at\": \"2026-01-05T05:37:26.316252\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "phase4_config = {\n",
    "    \"llm_provider\": \"groq\",\n",
    "    \"llm_model\": \"llama-3.3-70b-versatile\",\n",
    "    \"temperature\": 0,\n",
    "    \"intent_types\": [intent.value for intent in IntentType],\n",
    "    \"confidence_threshold\": 0.7,\n",
    "    \"max_context_messages\": 4,\n",
    "    \"test_results\": {\n",
    "        \"total_queries\": len(test_queries),\n",
    "        \"accuracy\": f\"{accuracy:.1f}%\",\n",
    "        \"avg_confidence\": f\"{avg_conf:.2f}\",\n",
    "        \"per_category\": {\n",
    "            category: {\n",
    "                \"accuracy\": f\"{(stats['correct'] / stats['total'] * 100):.1f}%\" if stats['total'] > 0 else \"N/A\",\n",
    "                \"total\": stats['total']\n",
    "            }\n",
    "            for category, stats in category_stats.items()\n",
    "        }\n",
    "    },\n",
    "    \"features\": [\n",
    "        \"intent_classification\",\n",
    "        \"clarification_generation\",\n",
    "        \"context_aware_classification\",\n",
    "        \"entity_extraction\",\n",
    "        \"mongodb_integration\"\n",
    "    ],\n",
    "    \"created_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save config\n",
    "config_path = project_root / \"phase4_config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(phase4_config, f, indent=2)\n",
    "\n",
    "print(\" Phase 4 config saved\")\n",
    "print(f\"   Location: {config_path}\")\n",
    "print(\"\\n Configuration Summary:\")\n",
    "print(json.dumps(phase4_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d6fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agri-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
